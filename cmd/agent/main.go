package main

import (
	"bytes"
	"encoding/json"
	"flag"
	"fmt"
	"io"
	"log"
	"net/http"
	"os"
	"sync"
	"time"
)

// Config Agenté…ç½®
type Config struct {
	ServerURL       string        // æœåŠ¡å™¨åœ°å€
	ProbeInterval   time.Duration // æ¢æµ‹é—´éš”
	TimeoutDuration time.Duration // å•æ¬¡æ¢æµ‹è¶…æ—¶æ—¶é—´
	MaxFileSize     int64         // æœ€å¤§ä¸‹è½½æ–‡ä»¶å¤§å°ï¼ˆå­—èŠ‚ï¼‰
	SpeedThreshold  float64       // é€Ÿåº¦é˜ˆå€¼ï¼ˆKB/sï¼‰ï¼Œç”¨äºåˆ¤æ–­æ˜¯å¦æˆåŠŸ
	Concurrency     int           // å¹¶å‘æ¢æµ‹æ•°é‡
}

// LinkItem é“¾æ¥é¡¹
type LinkItem struct {
	ID                   uint   `json:"id"`
	URL                  string `json:"url"`
	Name                 string `json:"name"`
	Description          string `json:"description"`
	Type                 string `json:"type"`
	Status               string `json:"status"`
	GroupID              *uint  `json:"group_id,omitempty"`
	GroupName            string `json:"group_name,omitempty"`
	ProbeEnabled         bool   `json:"probe_enabled"`
	ProbeIntervalMinutes int    `json:"probe_interval_minutes"`
	CreatedAt            string `json:"created_at"`
}

// AllLinksResponse æ‰€æœ‰é“¾æ¥çš„å“åº”
type AllLinksResponse struct {
	Links []LinkItem `json:"links"`
	Total int        `json:"total"`
}

// ProbeResult æ¢æµ‹ç»“æœ
type ProbeResult struct {
	URL            string  `json:"url"`
	SpeedKbps      float64 `json:"speed_kbps"`
	FileSize       *int64  `json:"file_size,omitempty"`
	DownloadTimeMs *int64  `json:"download_time_ms,omitempty"`
	Status         string  `json:"status"`
	ErrorMessage   string  `json:"error_message,omitempty"`
	UserAgent      string  `json:"user_agent"`
}

// BatchReportRequest æ‰¹é‡ä¸ŠæŠ¥è¯·æ±‚
type BatchReportRequest struct {
	Results []ProbeResult `json:"results"`
}

// ProbeHistory æ¢æµ‹å†å²è®°å½•ï¼ˆå­˜å‚¨åœ¨å†…å­˜ä¸­ï¼‰
type ProbeHistory struct {
	LastProbeTime map[string]time.Time // key: URL, value: ä¸Šæ¬¡æ¢æµ‹æ—¶é—´
	mu            sync.RWMutex
}

var probeHistory = &ProbeHistory{
	LastProbeTime: make(map[string]time.Time),
}

const probeHistoryFile = "probe_history.json"

// åŠ è½½æ¢æµ‹å†å²
func (h *ProbeHistory) Load() error {
	h.mu.Lock()
	defer h.mu.Unlock()

	data, err := os.ReadFile(probeHistoryFile)
	if err != nil {
		if os.IsNotExist(err) {
			log.Printf("ğŸ“ æ¢æµ‹å†å²æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°†åˆ›å»ºæ–°æ–‡ä»¶")
			return nil
		}
		return fmt.Errorf("è¯»å–æ¢æµ‹å†å²å¤±è´¥: %w", err)
	}

	var historyData map[string]string
	if err := json.Unmarshal(data, &historyData); err != nil {
		return fmt.Errorf("è§£ææ¢æµ‹å†å²å¤±è´¥: %w", err)
	}

	for url, timeStr := range historyData {
		t, err := time.Parse(time.RFC3339, timeStr)
		if err != nil {
			log.Printf("âš ï¸  è§£ææ—¶é—´å¤±è´¥ (URL: %s): %v", url, err)
			continue
		}
		h.LastProbeTime[url] = t
	}

	log.Printf("ğŸ“ åŠ è½½æ¢æµ‹å†å²: %d æ¡è®°å½•", len(h.LastProbeTime))
	return nil
}

// ä¿å­˜æ¢æµ‹å†å²
func (h *ProbeHistory) Save() error {
	h.mu.RLock()
	defer h.mu.RUnlock()

	historyData := make(map[string]string)
	for url, t := range h.LastProbeTime {
		historyData[url] = t.Format(time.RFC3339)
	}

	data, err := json.MarshalIndent(historyData, "", "  ")
	if err != nil {
		return fmt.Errorf("åºåˆ—åŒ–æ¢æµ‹å†å²å¤±è´¥: %w", err)
	}

	if err := os.WriteFile(probeHistoryFile, data, 0644); err != nil {
		return fmt.Errorf("ä¿å­˜æ¢æµ‹å†å²å¤±è´¥: %w", err)
	}

	log.Printf("ğŸ’¾ ä¿å­˜æ¢æµ‹å†å²: %d æ¡è®°å½•", len(h.LastProbeTime))
	return nil
}

func main() {
	// è§£æå‘½ä»¤è¡Œå‚æ•°
	serverURL := flag.String("server", "http://16.163.99.99:8080", "æœåŠ¡å™¨åœ°å€")
	interval := flag.Duration("interval", 10*time.Minute, "æ¢æµ‹é—´éš”")
	timeout := flag.Duration("timeout", 60*time.Second, "å•æ¬¡æ¢æµ‹è¶…æ—¶æ—¶é—´")
	maxSize := flag.Int64("max-size", 10*1024*1024, "æœ€å¤§ä¸‹è½½æ–‡ä»¶å¤§å°ï¼ˆå­—èŠ‚ï¼‰")
	speedThreshold := flag.Float64("speed-threshold", 10.0, "é€Ÿåº¦é˜ˆå€¼ï¼ˆKB/sï¼‰")
	concurrency := flag.Int("concurrency", 50, "å¹¶å‘æ¢æµ‹æ•°é‡")
	flag.Parse()

	config := Config{
		ServerURL:       *serverURL,
		ProbeInterval:   *interval,
		TimeoutDuration: *timeout,
		MaxFileSize:     *maxSize,
		SpeedThreshold:  *speedThreshold,
		Concurrency:     *concurrency,
	}

	log.Printf("ğŸš€ Agent å¯åŠ¨")
	log.Printf("   æœåŠ¡å™¨åœ°å€: %s", config.ServerURL)
	log.Printf("   æ¢æµ‹é—´éš”: %v", config.ProbeInterval)
	log.Printf("   æ¢æµ‹è¶…æ—¶: %v", config.TimeoutDuration)
	log.Printf("   æœ€å¤§æ–‡ä»¶å¤§å°: %d MB", config.MaxFileSize/(1024*1024))
	log.Printf("   é€Ÿåº¦é˜ˆå€¼: %.2f KB/s", config.SpeedThreshold)
	log.Printf("   å¹¶å‘æ•°é‡: %d", config.Concurrency)

	// åŠ è½½æ¢æµ‹å†å²
	if err := probeHistory.Load(); err != nil {
		log.Printf("âš ï¸  åŠ è½½æ¢æµ‹å†å²å¤±è´¥: %v", err)
	}

	// ç«‹å³æ‰§è¡Œä¸€æ¬¡
	log.Println("â° å¼€å§‹é¦–æ¬¡æ¢æµ‹...")
	runProbe(&config)

	// å®šæ—¶æ‰§è¡Œ
	ticker := time.NewTicker(config.ProbeInterval)
	defer ticker.Stop()

	for range ticker.C {
		log.Printf("â° å¼€å§‹å®šæ—¶æ¢æµ‹...")
		runProbe(&config)
	}
}

// runProbe æ‰§è¡Œä¸€æ¬¡å®Œæ•´çš„æ¢æµ‹æµç¨‹
func runProbe(config *Config) {
	startTime := time.Now()

	// 1. è·å–æ‰€æœ‰é“¾æ¥
	links, err := fetchAllLinks(config.ServerURL)
	if err != nil {
		log.Printf("âŒ è·å–é“¾æ¥å¤±è´¥: %v", err)
		return
	}

	log.Printf("ğŸ“‹ è·å–åˆ° %d ä¸ªé“¾æ¥", links.Total)

	// 2. æ ¹æ®åˆ†ç»„è®¾ç½®è¿‡æ»¤å’Œæ”¶é›†URL
	type urlInfo struct {
		url      string
		interval time.Duration
	}

	urlMap := make(map[string]urlInfo) // key: URL, value: urlInfo
	now := time.Now()

	skippedDisabled := 0
	skippedInterval := 0

	for _, link := range links.Links {
		if link.URL == "" {
			continue
		}

		// æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨è¯¥URL
		if _, exists := urlMap[link.URL]; exists {
			continue
		}

		// æ£€æŸ¥æ˜¯å¦å¯ç”¨æ¢æµ‹
		if !link.ProbeEnabled {
			log.Printf("â­ï¸  è·³è¿‡ï¼ˆæ¢æµ‹å·²ç¦ç”¨ï¼‰: %s (åˆ†ç»„: %s)", link.URL, link.GroupName)
			skippedDisabled++
			continue
		}

		// æ£€æŸ¥æ¢æµ‹é—´éš”
		probeInterval := time.Duration(link.ProbeIntervalMinutes) * time.Minute
		probeHistory.mu.RLock()
		lastProbeTime, hasHistory := probeHistory.LastProbeTime[link.URL]
		probeHistory.mu.RUnlock()

		if hasHistory {
			timeSinceLastProbe := now.Sub(lastProbeTime)
			if timeSinceLastProbe < probeInterval {
				remainingTime := probeInterval - timeSinceLastProbe
				log.Printf("â³ è·³è¿‡ï¼ˆæœªåˆ°æ¢æµ‹é—´éš”ï¼‰: %s (åˆ†ç»„: %s, é—´éš”: %dåˆ†é’Ÿ, è·ä¸Šæ¬¡: %.1fåˆ†é’Ÿ, è¿˜éœ€: %.1fåˆ†é’Ÿ)",
					link.URL, link.GroupName, link.ProbeIntervalMinutes,
					timeSinceLastProbe.Minutes(), remainingTime.Minutes())
				skippedInterval++
				continue
			}
		}

		// æ·»åŠ åˆ°æ¢æµ‹åˆ—è¡¨
		urlMap[link.URL] = urlInfo{
			url:      link.URL,
			interval: probeInterval,
		}
	}

	// æå–URLåˆ—è¡¨
	var urls []string
	for _, info := range urlMap {
		urls = append(urls, info.url)
	}

	log.Printf("ğŸ” è¿‡æ»¤åéœ€è¦æ¢æµ‹ %d ä¸ªURLï¼ˆè·³è¿‡ï¼šç¦ç”¨ %d ä¸ªï¼Œæœªåˆ°é—´éš” %d ä¸ªï¼‰",
		len(urls), skippedDisabled, skippedInterval)

	// 3. å¹¶å‘æ¢æµ‹æ‰€æœ‰URL
	results := make([]ProbeResult, 0, len(urls))
	var resultsMutex sync.Mutex
	var wg sync.WaitGroup

	// åˆ›å»ºå¹¶å‘æ§åˆ¶çš„ semaphore channel
	semaphore := make(chan struct{}, config.Concurrency)

	successCount := 0
	failedCount := 0
	var statsMutex sync.Mutex

	completed := 0
	var completedMutex sync.Mutex

	for _, url := range urls {
		wg.Add(1)
		go func(targetURL string) {
			defer wg.Done()

			// è·å–ä¿¡å·é‡
			semaphore <- struct{}{}
			defer func() { <-semaphore }()

			// è·å–å½“å‰è¿›åº¦
			completedMutex.Lock()
			completed++
			currentIndex := completed
			completedMutex.Unlock()

			log.Printf("   [%d/%d] æ¢æµ‹: %s", currentIndex, len(urls), targetURL)

			result := probeURL(targetURL, config)

			// ä¿å­˜ç»“æœ
			resultsMutex.Lock()
			results = append(results, result)
			resultsMutex.Unlock()

			// æ›´æ–°æ¢æµ‹å†å²
			probeHistory.mu.Lock()
			probeHistory.LastProbeTime[targetURL] = time.Now()
			probeHistory.mu.Unlock()

			// æ›´æ–°ç»Ÿè®¡
			statsMutex.Lock()
			if result.Status == "success" {
				successCount++
				log.Printf("   âœ“ æˆåŠŸ | é€Ÿåº¦: %.2f KB/s | è€—æ—¶: %d ms",
					result.SpeedKbps, *result.DownloadTimeMs)
			} else {
				failedCount++
				log.Printf("   âœ— å¤±è´¥ | åŸå› : %s", result.ErrorMessage)
			}
			statsMutex.Unlock()
		}(url)
	}

	// ç­‰å¾…æ‰€æœ‰æ¢æµ‹å®Œæˆ
	wg.Wait()

	// 4. æ‰¹é‡ä¸ŠæŠ¥ç»“æœ
	log.Printf("ğŸ“¤ ä¸ŠæŠ¥æ¢æµ‹ç»“æœ...")
	if err := reportResults(config.ServerURL, results); err != nil {
		log.Printf("âŒ ä¸ŠæŠ¥å¤±è´¥: %v", err)
	} else {
		log.Printf("âœ… ä¸ŠæŠ¥æˆåŠŸ")
	}

	// 5. ä¿å­˜æ¢æµ‹å†å²
	if err := probeHistory.Save(); err != nil {
		log.Printf("âš ï¸  ä¿å­˜æ¢æµ‹å†å²å¤±è´¥: %v", err)
	}

	// 6. è¾“å‡ºç»Ÿè®¡
	elapsed := time.Since(startTime)
	log.Printf("ğŸ“Š æœ¬æ¬¡æ¢æµ‹å®Œæˆ")
	log.Printf("   æ€»è€—æ—¶: %v", elapsed)
	log.Printf("   æ¢æµ‹æ€»æ•°: %d", len(urls))
	log.Printf("   æˆåŠŸ: %d (%.1f%%)", successCount, float64(successCount)*100/float64(len(urls)))
	log.Printf("   å¤±è´¥: %d (%.1f%%)", failedCount, float64(failedCount)*100/float64(len(urls)))
	log.Println()
}

// fetchAllLinks è·å–æ‰€æœ‰é“¾æ¥
func fetchAllLinks(serverURL string) (*AllLinksResponse, error) {
	url := fmt.Sprintf("%s/api/v1/all-links", serverURL)

	resp, err := http.Get(url)
	if err != nil {
		return nil, fmt.Errorf("è¯·æ±‚å¤±è´¥: %w", err)
	}
	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		body, _ := io.ReadAll(resp.Body)
		return nil, fmt.Errorf("HTTP %d: %s", resp.StatusCode, string(body))
	}

	var result AllLinksResponse
	if err := json.NewDecoder(resp.Body).Decode(&result); err != nil {
		return nil, fmt.Errorf("è§£æå“åº”å¤±è´¥: %w", err)
	}

	return &result, nil
}

// probeURL æ¢æµ‹å•ä¸ªURLçš„ä¸‹è½½é€Ÿåº¦ï¼ˆæ”¯æŒé‡è¯•ï¼‰
func probeURL(url string, config *Config) ProbeResult {
	const maxRetries = 3

	for attempt := 1; attempt <= maxRetries; attempt++ {
		result := probeURLOnce(url, config)

		// å¦‚æœæˆåŠŸæˆ–éè¶…æ—¶é”™è¯¯ï¼Œç›´æ¥è¿”å›
		if result.Status == "success" || result.Status != "timeout" {
			return result
		}

		// è¶…æ—¶ä¸”è¿˜æœ‰é‡è¯•æœºä¼š
		if attempt < maxRetries {
			log.Printf("   âš ï¸  è¶…æ—¶ï¼Œ%dç§’åé‡è¯• (%d/%d)", 2, attempt, maxRetries)
			time.Sleep(2 * time.Second)
		} else {
			// æœ€åä¸€æ¬¡é‡è¯•ä¹Ÿå¤±è´¥äº†
			result.ErrorMessage = fmt.Sprintf("è¯·æ±‚è¶…æ—¶(å·²é‡è¯•%dæ¬¡): %s", maxRetries, result.ErrorMessage)
			return result
		}
	}

	// ä¸åº”è¯¥åˆ°è¿™é‡Œï¼Œä½†ä¸ºäº†å®‰å…¨è¿”å›å¤±è´¥
	return ProbeResult{
		URL:          url,
		UserAgent:    "SpeedProbeAgent/1.0",
		Status:       "failed",
		ErrorMessage: "æœªçŸ¥é”™è¯¯",
	}
}

// probeURLOnce æ‰§è¡Œå•æ¬¡URLæ¢æµ‹
func probeURLOnce(url string, config *Config) ProbeResult {
	result := ProbeResult{
		URL:       url,
		UserAgent: "SpeedProbeAgent/1.0",
		Status:    "failed",
	}

	// åˆ›å»ºHTTPå®¢æˆ·ç«¯
	client := &http.Client{
		Timeout: config.TimeoutDuration,
	}

	// è®°å½•å¼€å§‹æ—¶é—´
	startTime := time.Now()

	// å‘èµ·è¯·æ±‚ï¼ˆä½¿ç”¨ Range å¤´åªè¯·æ±‚å‰30KBï¼‰
	const maxDownloadSize = 30 * 1024 // 100KB
	req, err := http.NewRequest("GET", url, nil)
	if err != nil {
		result.ErrorMessage = fmt.Sprintf("åˆ›å»ºè¯·æ±‚å¤±è´¥: %v", err)
		return result
	}
	req.Header.Set("User-Agent", result.UserAgent)
	req.Header.Set("Range", fmt.Sprintf("bytes=0-%d", maxDownloadSize-1)) // è¯·æ±‚å‰100KB

	resp, err := client.Do(req)
	if err != nil {
		result.ErrorMessage = fmt.Sprintf("è¯·æ±‚å¤±è´¥: %v", err)
		result.Status = "timeout"
		return result
	}
	defer resp.Body.Close()

	// æ£€æŸ¥HTTPçŠ¶æ€ç ï¼ˆ206 Partial Content æˆ– 200 OK éƒ½å¯ä»¥ï¼‰
	if resp.StatusCode != http.StatusOK && resp.StatusCode != http.StatusPartialContent {
		result.ErrorMessage = fmt.Sprintf("HTTP %d", resp.StatusCode)
		return result
	}

	// ä¸‹è½½å†…å®¹å¹¶è®¡ç®—é€Ÿåº¦
	totalSize := int64(0)
	buffer := make([]byte, 32*1024) // 32KB buffer

	for {
		n, err := resp.Body.Read(buffer)
		if n > 0 {
			totalSize += int64(n)
		}

		if err == io.EOF {
			break
		}
		if err != nil {
			result.ErrorMessage = fmt.Sprintf("è¯»å–å¤±è´¥: %v", err)
			return result
		}
	}

	// è®¡ç®—è€—æ—¶å’Œé€Ÿåº¦
	downloadTime := time.Since(startTime)
	downloadTimeMs := downloadTime.Milliseconds()
	speedKbps := float64(totalSize) / 1024.0 / downloadTime.Seconds()

	result.FileSize = &totalSize
	result.DownloadTimeMs = &downloadTimeMs
	result.SpeedKbps = speedKbps

	// åˆ¤æ–­æ˜¯å¦æˆåŠŸï¼ˆåŸºäºé€Ÿåº¦é˜ˆå€¼ï¼‰
	if speedKbps >= config.SpeedThreshold {
		result.Status = "success"
	} else {
		result.Status = "failed"
		result.ErrorMessage = fmt.Sprintf("é€Ÿåº¦è¿‡æ…¢: %.2f KB/s < %.2f KB/s", speedKbps, config.SpeedThreshold)
	}

	return result
}

// reportResults æ‰¹é‡ä¸ŠæŠ¥æ¢æµ‹ç»“æœ
func reportResults(serverURL string, results []ProbeResult) error {
	url := fmt.Sprintf("%s/api/v1/speed-probe/report-batch", serverURL)

	reqBody := BatchReportRequest{
		Results: results,
	}

	jsonData, err := json.Marshal(reqBody)
	if err != nil {
		return fmt.Errorf("åºåˆ—åŒ–å¤±è´¥: %w", err)
	}

	resp, err := http.Post(url, "application/json", bytes.NewBuffer(jsonData))
	if err != nil {
		return fmt.Errorf("è¯·æ±‚å¤±è´¥: %w", err)
	}
	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		body, _ := io.ReadAll(resp.Body)
		return fmt.Errorf("HTTP %d: %s", resp.StatusCode, string(body))
	}

	return nil
}
